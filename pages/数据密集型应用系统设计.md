- 可靠、可扩展与可维护的应用系统
	- 可靠、可扩展与可维护
		- 可靠性
			- 容忍硬件、软件失效、人为错误
		- 可扩展性
			- 评测负载与性能，延迟百分位数，吞吐量
		- 可维护性
			- 可运维、简单与可演化性
	- 当今许多新型应用都属于数据密集型( data-intensive)，而不是计算密集型 (compute-intensive)
		- 对于这些类型应用， CPU的处理能力往往不是第一限制性因素，关键在于数据量、数据的复杂度及数据的快速多变性。
	- 数据系统(data systems)
		- 例子
			- 数据库:用以存储数据，这样之后应用可以再次面问。
			- 高速缓存 : 缓存那些复杂或操作代价昂贵的结果，以加快下一次访问。
			- 索引 : 用户可以按关键字搜索数据井支持各种过掳 。
			- 流式处理:持续发送消息至另 一 个进程，处理采用异步方式。
			- 批处理 : 定期处理大量的累积数据。
		- 为什么本书将它们归为一大类即“数据系统” (data system)
			- 近年来出现了许多用于数据存储和处理的新工具 。 它们针对各种不同的应用场景进行优化，不适合再归为传统类型
				- 系统之间的界限正在变得模糊。
			- 越来越多的应用系统需求广泛，单个组件往往无能满足所有数据处理与存储需求。
				- 因而需要将任务分解，每个组件负责高效完成其中一部分，多个组件依靠应用层代码驱动有机衔接起来。
		- 本书将专注于对大多数软件系统都极为重要的 三个问题
			- 可靠性 (Reliability)
				- 当出现意外情况如硬件、软件故障、人为失误等，系统应可以继续正常运转：虽然性能可能有所降低，但确保功能正确。
				- 对于软件，典型的可靠性期望包括
					- 应用程序执行用户所期望的功能。
					- 可以容忍用户出现错误或者不正确的软件使用方法
					- 性能可以应对典型场景 、 合理负载压力和数据量
					- 系统可防止任何未经授权的访问和滥用
				- 我们可以认为可靠性大致意味着
					- 即使发生了某些错误，系统仍可以继续正常工作。
						- 可能出错的事情称为错误( faults)或故障，系统可应对错误则称为容错( fau lt­ tolerant)或者弹性( resilient)。
							- 注意，故障与失效( failure) 不完全一致[2]。故障通常被定义为组件偏离其正常规格，而失效意味系统作为一个整体停止，无法向用户提供所需的服务。
						- 在这种容错系统中，用于测试目的，可以故意提高故障发生概率
							- 通过这种故意引发故障的方式，来持续检验、测试系统的容错机制，增加对真实发生故障时应对的信心。
				- 故障类型
					- 硬件故障
						- 例子
							- 有研究证明硬盘的平均无故障时间( MTTF)约为 10~ 50年[5,6)。
								- 因此，在一个包括 10 000个磁盘的存储集群中，我们应该预期平均每天有一个磁盘发生故障。
						- 解法
							- 我们的第一个反应通常是为硬件添加冗余来减少系统故障率。
								- 例如对磁盘配置 RAID，服务器配备双电源，甚至热插拔CPU， 数据中心添加备用电惊、发电机等。
								- 当一个组件发生故障，冗余组件可以快速接管，之后再更换失效的组件。
									- 这种方法可能并不能完全防止硬件故障所引发的失效，但还是被普遍采用，且在实际中也确实可以让系统不间断运行长达数年。
								- 直到最近，采用硬件冗余方案对于大多数应用场景还是足够的，它使得单台机器完全失效的概率降为非常低的水平。
									- 只要可以将备份迅速恢复到新机器上，故障的停机时间在大多数应用中并不是灾难性的。
									- 而多机冗余则只对少量的关键应用更有意义，对于这些应用，高可用性是绝对必要的。
						- 问题
							- 但是，随着数据量和应用计算需求的增加，更多的应用可以运行在大规模机器之上，随之而来的硬件故障率呈线性增长。
								- 例如，对于某些云平台(如 Amazon Web Services , AWS )，由于系统强调的是总体灵活性与弹性，而非单台机器的可靠性， 虚拟机实例经常会在事先无告警的情况下出现无法访问问题。
							- 因此，通过软件容错的方式来容忍多机失效成为新的手段，或者至少成为硬件容错的有力补充。
								- 这样的系统更具有操作便利性，例如当需要重启计算机时为操作系统打安 全补丁，可以每次给一 个节点打补丁然后重启，而不需要同时下线整个系统(即滚动升级，详见第4章)
						- 硬件故障多是相互独立的
							- 我们通常认为硬件故障之 间多是相互独立的: 一台机器的磁盘出现故障并不意味着另 一台机器的磁盘也要失效。
							- 除非存在某种弱相关(例如一些共性原因，如服务器机架 中的温度过高)，否 则 通常不太可能出现大量硬件组件同时失效的情况。
					- 软件错误
						- 系统内的软件问题
							- 这些故障事先更加难以预料，而且因为节点之 间是由软件关联的，因而往往会导致更多的系统故障
						- 例子
							- 由于软件错误，导致当输入特定值时应用服务器总是崩溃。
							- 一个应用进程使用了某些共享资源如CPU、内存、磁盘或网络带宽 ，但却不幸失控跑飞了。
							- 系统依赖于某些服务，但该服务突然变慢，甚至无晌应或者开始返回异常的晌
							  应。
							- 级联故障，其中某个组件的小故障触发另一个组件故障，进而引发更多的系统问题
						- 导致软件故障的bug通常会长时间处于引而不发的状态，直到碰到特定的触发条件。
						- 这也意味着系统软件其实对使用环境存在某种假设，而这种假设多数情况都可以满足，但是在特定情况下，假设条件变得不再成立。
						- 软件系统问题有时没有快速解决办法，而只能仔细考虑很多细节
							- 包括认真检查依赖的假设条件与系统之间交互 ，进行全面的测试，
							- 进程隔离，
							- 允许进程崩溃并自动重启，
							- 反复评估，监控井分析生产环节的行为表现等。
								- 如果系统提供某些保证，例如，在消息队列中，输出消息的数量应等于输入消息的数量， 则可以不断地检查确认 ，如发现差异则立即告警
					- 人为失误
						- 人却无怯做到万无一失
							- 例子：
								- 一项针对大型互联网服务的调查发现，运 维者的配置错误居然是系统下线的首要原因，而硬件问题(服务器或网络)仅在 10%~25%的故障中有所影响
									- David Oppenheimer, Archana Ganapathi, and David A. Patterson:“Why Do Internet Services Fail, and What Can Be Done About It?,” at 4th USENIX Symposium on Internet Technologies and Systems (USITS), March 2003 .
						- 如何解决
							- 以最小出错的方式来设计系统。
								- 例如，精心设计的抽象层、 API以及管理界面，使“做正确的事情”很轻松，但搞坏很复杂。
								- 但是，如果限制过多，人们就会想法来绕过它，这会抵消其正面作用。
								- 因此解决之道在于很好的平衡。
							- 想办法分离最容易出错的地方、容易引发故障的接口。
								- 特别是，提供一个功能齐全但非生产用的沙箱环境，使人们可以放心的尝试、体验，包括导入真实的数据，万一出现问题，不会影响真实用户。
							- 充分的测试:从各单元测试到全系统集成测试以及手动测试
								- 自动化测试已被广泛使用，对于覆盖正常操作中很少出现的边界条件等尤为重要。
							- 当出现人为失误时，提供快速的恢复机制以尽量减少故障影响。
								- 例如，快速回滚配置改动，滚动发布新代码(这样任何意外的错误仅会影响一小部分用户)，并提供校验数据的工具(防止旧的计算方式不正确)。
							- 设置详细而清晰的监控子系统，包括性能指标和错误率。
								- 在其他行业称为遥测 (Telemetry)， 一旦火箭离开地面，遥测对于跟踪运行和了解故障至关重要。
								- 监控可以向我们发送告警信号，井检查是否存在假设不成立或违反约束条
								  件等。
								- 这些检测指标对于诊断问题也非常有用。
							- 推行管理流程井加以培训。
								- 这非常重要而且比较复杂
				- 可靠性的重要性
					- 很多应用都需要可靠工作。
						- 商业软件中的错误会导致效率下降(如数据报告错误，甚至带来怯律风险)，电子商务网站的暂停会对营收和声誉带来巨大损失。
					- 即使在所谓“非关键”应用中，我们也应秉持对用户负责的态度
					- 当然，也会存在其他一些情况，例如面对不太确定的市场开发原型系统，或者服务的利润微薄，有时也会牺牲一些可靠性来降低开发成本或者运营开销，对此，我们总是建议务必三思后行。
			- 可扩展性 (Scalability)
				- 随着规模的增长 ，例如数据量 、流量或复杂性，系统应以合理的方式来匹配这种增长
				-
			- 可维护性 (Maintainability)
				- 随着时间的推移，许多新的人员参与到系统开发和运维， 以维护现有功能或适配 新场景等，系统都应高效运转。
			-