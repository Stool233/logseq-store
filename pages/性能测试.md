- 性能领域、性能测试、容量测试、基准测试、性能分析
- 《性能之巅》整理
  collapsed:: true
	- [[系统性能]]
		- 系统性能是对整个系统的研究，包括了所有的硬件组件和整个软件栈。
		- 所有数据路径上和软硬件上所发生的事情都包括在内。
		- ![image.png](../assets/image_1646147314960_0.png){:height 341, :width 426}
	- 人员
		- 系统性能是一项需要多类人员参与的事务。
	- 事情
		- [[性能]]领域包括的事情（按理想顺序排列）
			- 1 设置性能目标和建立性能模型
			- 2 基于软件或硬件原型进行性能特征归纳
			- 3 对开发代码进行[[性能分析]](软件整合之前)
			- 4 执行软件非回归性测试 (软件发布前或发布后)
			- 5 针对软件发布版本的[[基准测试]]
			- 6 目标环境中的概念验证( Proof-of-concept )测试
			- 7 生产环境部署的配置优化
			- 8 监控生产环境中运行的软件
			- 9 特定问题的[[性能分析]]
		- 术语[[容量规划]]
			- 指的是一系列事前行动。在设计阶段，包括通过研究开发软件的资源占用情况，来得知原有设计在多大程度上能满足目标需求。在部署后,包括监控资源的使用情况，这样问题在出现之前就能被预测。
	- 视角
		- 两种性能分析的视角
			- [[负载分析]]（workload analysis）
			- [[资源分析]]（resource analysis）
		- ![image.png](../assets/image_1646147812645_0.png){:height 264, :width 445}
		- 系统管理员作为系统资源的负责人，通常采用[[资源分析]]视角。
		- 应用程序开发人员，对最终实现的负载性能负责，通常采用[[负载分析]]视角。
	- [[性能]]是充满挑战的
		- 性能是主观的
			- 开始着手性能问题的时候，对问题是否存在的判断都有可能是模糊的，在问题被修复的时候也同样。
			- 从某种程度上说，一个给定指标是“好”或“坏”取决于应用开发人员和最终用户的性能预期。
			- 通过定义清晰的目标，可以吧主观的性能变得客观化
				- 诸如目标平均响应时间、或者对落进一定响应延时范围内的请求统计其百分比。
		- 系统是[[复杂]]的
			- 组件的互联
				- 性能问题可能出在子系统之间复杂的互联上，即使这些子系统隔离时表现得都很好。
				- 也可能由于连锁故障（cascading failure）出现性能问题，这指的是一个出现故障的组件会导致其他组件产生性能问题。
			- 问题的关联
				- 修复一个问题可能只是把瓶颈推向了系统里的其他地方，导致整体性能没有提升。
			- 生产环境负载的复杂特性
				- 实验室环境很难重现这类情况，或者只能间歇式地重现。
			- 解决复杂的性能问题常常需要全局性的方法
				- 整个系统——包括自身内部和外部的交互——都可能需要被调查研究。
		- 可能有多个问题并存
			- 真正的任务不是寻找问题，而是辨别哪些问题是最重要的
			- 性能分析必须量化问题的重要程度。
	- [[量化]]性能的指标举例
		- 延时
			- 有一个指标非常适合用来量化性能，那就是延时( latency )。
			- 延时测量的是用于等待的时间。广义来说，它可以表示所有操作完成的耗时
			- 虽然延时是一个非常有用的指标，但也不是随时随地都能获得。
				- 某些系统只有平均延时，某些系统则完全没有延时指标。
				- [[动态跟踪]]( dynamic tracing )可以从任意感兴趣的点测量延时，还可以提供数据以显示延时完整的分布情况。
	- [[动态跟踪]]
		- 动态跟踪技术把所有的软件变得可以监控，而且能用在真实的生产环境中。
		- 这项技术利用内存中的CPU指令并在这些指令之上动态构建监测数据。
			- 这样从任何运行的软件中都可以获得定制化的性能统计数据，从而提供了远超系统的自带统计所能给予的观测性。
				- 从前因为不易观测而无法处理的问题变得可以解决。
				- 从前可以解决而难以解决的问题，现在也往往可以得以简化。
		- 举例
			- DTrace
				- 在DTrace之前，系统跟踪( system tracing )常常使用静态探针( static probes) :置于内核和其他软件之上的一小套监测点。这种方法的观测是有限的，一般用起来很费时，需要配置、跟踪、导出数据以及最后分析一整套流程。
				- DTrace对用户态和内核态的软件都提供了静态跟踪和动态跟踪，并且数据是实时产生的。
	- [[云计算]]
		- 给系统性能带来影响的最新进展来自云计算和云计算的根基——虚拟技术的兴起。
		- 云计算采用的架构能让应用程序均衡分布于数目不断增多的小型系统中，这让快速扩展成为可能。
			- 这种方法还降低了对[[容量规划]]的精确程度的要求，因为更多的容量可以很便捷地在云端添加。
		- 在某些情况下，它对[[性能分析]]的需求更高了
			- 使用较少的资源就意味着系统更少。
			  id:: 621f58d3-18bb-4579-b65b-320d7cd893b7
				- 云的使用通常是按小时计费的，性能的优势可以减少系统的使用数目，从而直接节约成本。这和企业用户的情况不同，企业用户被一个支持协议锁定数年，直到合同终结都可能无法实现成本的节约。
		- [[云计算]]和[[虚拟化]]技术也带来了新的难题，这包括
			- 如何管理其他[[租户]]( tenant,有时被称作性能隔离( performance isolation) )带来的性能影响，以及如何让每个租户都能对物理系统做观测。
				- 举个例子，除非系统管理得很好，否则磁盘I/O性能可能因为同邻近租户的竞争而下降。
			- 在某些环境中，并不是每一个租户都能观察到物理磁盘的真实使用情况，这让问题的甄别变得困难。
		-
- 软件测试52讲 性能测试篇
	- 解读不同视角的软件性能与性能指标
		- 当我们谈及软件性能的时候，我们到底谈的是什么？
			- 目前，对软件性能最普遍的理解就是软件处理的及时性。
			- 但其实，从不同的系统类型，以及不同的视角去讨论软件性能，都会有所区别。
				- 对于不同类型的系统，软件性能的关注点各不相同
					- Web 类应用和手机端应用，一般以终端用户感受到的端到端的响应时间来描述系统的性能；
					- 非交互式的应用，比如典型的电信和银行后台处理系统，响应时间关注更多的是事件处理的速度，以及单位时间的事件吞吐量。
				- 同样地，对同一个系统来说，不同的对象群体对软件性能的关注点和期望也不完全相同，甚至很多时候是对立的。
					- 这里，不同的对象群体可以分为四大类：终端用户、系统运维人员、软件设计开发人员和性能测试人员。
		- 终端用户眼中的软件性能
			- 从终端用户（也就是软件系统使用者）的维度来讲，软件性能表现为用户进行业务操作时的主观响应时间。
				- 具体来讲就是，从用户在界面上完成一个操作开始，到系统把本次操作的结果以用户能察觉的方式展现出来的全部时间。
					- 对终端用户来说，这个时间越短体验越好
			- 这个响应时间是终端用户对系统性能的最直观印象，包括了系统响应时间和前端展现时间。
				- 系统响应时间
					- 反应的是系统能力，又可以进一步细分为应用系统处理时间、数据库处理时间和网络传输时间等；
				- 前端展现时间
					- 取决于用户端的处理能力。
		- 系统运维人员眼中的软件性能
			- 从软件系统运维（也就是系统运维人员）的角度，软件性能除了包括单个用户的响应时间外，更要关注
				- 大量用户并发访问时的负载，可能的更大负载情况下的系统健康状态、并发处理能力、当前部署的系统容量、可能的系统瓶颈、系统配置层面的调优、数据库的调优，以及长时间运行稳定性和可扩展性。
			-